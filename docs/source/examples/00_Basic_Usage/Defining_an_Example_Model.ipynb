{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Defining an Example Model\n",
    "\n",
    "In the next section, we define a simple 2-layer sparse DGP model for a regression task. Weâ€™ll be using this model to demonstrate the usage of the library."
   ],
   "id": "1b1e2221e44c7cac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T23:36:04.050268Z",
     "start_time": "2024-05-22T23:36:02.893950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import dgp_sparse as gp\n",
    "from dgp_sparse.layers.linear import LinearReparameterization\n",
    "from dgp_sparse.layers.activation import TMGP"
   ],
   "id": "initial_id",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Defining a 2-layer DTMGP Model\n",
    "\n",
    "First, we define a 2-layer DTMGP model with a single output dimension. The model consists of two layers, each with level-3 sparse grid design."
   ],
   "id": "7767bd7948758eb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T23:36:04.056501Z",
     "start_time": "2024-05-22T23:36:04.051242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a 2-layer DTMGP model for regression\n",
    "class SparseDGP_grid(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, design_class, kernel):\n",
    "        super(SparseDGP_grid, self).__init__()\n",
    "        \n",
    "        # 1st layer of DGP: input:[n, input_dim] size tensor, output:[n, w1] size tensor\n",
    "        self.tmk1 = TMGP(in_features=input_dim, n_level=3, design_class=design_class, kernel=kernel)\n",
    "        self.fc1 = LinearReparameterization(\n",
    "            in_features=self.tmk1.out_features, \n",
    "            out_features=8, \n",
    "            prior_mean=0.0, \n",
    "            prior_variance=1.0, \n",
    "            posterior_mu_init=0.0, \n",
    "            posterior_rho_init=-3.0, \n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        # 2nd layer of DGP: input:[n, w1] size tensor, output:[n, output_dim] size tensor\n",
    "        self.tmk2 = TMGP(in_features=8, n_level=3, design_class=design_class, kernel=kernel)\n",
    "        self.fc2 = LinearReparameterization(\n",
    "            in_features=self.tmk2.out_features, \n",
    "            out_features=output_dim, \n",
    "            prior_mean=0.0, \n",
    "            prior_variance=1.0, \n",
    "            posterior_mu_init=0.0, \n",
    "            posterior_rho_init=-3.0, \n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        kl_sum = 0\n",
    "\n",
    "        x = self.tmk1(x)\n",
    "        x, kl = self.fc1(x)\n",
    "        kl_sum += kl\n",
    "\n",
    "        x = self.tmk2(x)\n",
    "        x, kl = self.fc2(x)\n",
    "        kl_sum += kl\n",
    "\n",
    "        return torch.squeeze(x), kl_sum"
   ],
   "id": "5f19e34aab5634b8",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preparing the Data\n",
    "\n",
    "We set up the training data for this example. We'll be using 1000 regularly spaced points in the range [0, 10] as input data. The output data is generated by a function that takes the input data and adds Gaussian noise to get the training labels."
   ],
   "id": "4681af98afe7c813"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T23:36:04.065586Z",
     "start_time": "2024-05-22T23:36:04.056501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_X = torch.linspace(0, 1, 1000)\n",
    "train_y = 3 * train_X + 2 + torch.randn(train_X.size()) * 0.1\n",
    "\n",
    "class RegressionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "dataset = RegressionDataset(train_X, train_y)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ],
   "id": "ae83117d86eb8504",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initializing the Model and the Optimizer",
   "id": "73f0a7e87bd85a2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T23:36:05.548184Z",
     "start_time": "2024-05-22T23:36:04.066287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dgp_sparse.utils.sparse_design.design_class import HyperbolicCrossDesign\n",
    "from dgp_sparse.kernels.laplace_kernel import LaplaceProductKernel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using: \", device)\n",
    "\n",
    "model = SparseDGP_grid(input_dim=1, \n",
    "                       output_dim=1, \n",
    "                       design_class=HyperbolicCrossDesign, \n",
    "                       kernel=LaplaceProductKernel(1.),\n",
    "                       ).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ],
   "id": "60d11360be6a6280",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training the Model\n",
    "\n",
    "In the next cell, we handle using variational inference (VI) to train the 2-layer sparse DGP model."
   ],
   "id": "440609ecdd176828"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T23:36:15.507400Z",
     "start_time": "2024-05-22T23:36:05.549198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_ = []\n",
    "        kl_ = []\n",
    "        for mc_run in range(1):\n",
    "            output, kl = model(data)\n",
    "            output_.append(output)\n",
    "            kl_.append(kl)\n",
    "        output = torch.mean(torch.stack(output_), dim=0)\n",
    "        kl = torch.mean(torch.stack(kl_), dim=0)\n",
    "        nll_loss = F.mse_loss(output, target)\n",
    "        # ELBO loss\n",
    "        loss = nll_loss + (kl / 32)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ],
   "id": "8f8ef20ddad946c1",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "See our [documentation](https://sparse-dgp.readthedocs.io/en/latest/) for more information on how to use the library.",
   "id": "1ca660770bc27323"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
